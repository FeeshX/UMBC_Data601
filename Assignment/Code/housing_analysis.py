# -*- coding: utf-8 -*-
"""Housing_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CdncOohPMg3mOnPT-hziYuQ4nefGPME5

## **The Housing Market During the COVID-19 Pandemic**
**Exploratory Analysis**
"""

#Mounting data file from local Google Drive

from google.colab import drive
drive.mount("/content/drive")

#Converting the file from .tsv to .csv for ease of data analyis. 
#Tab Separated Values (TSV)and Comma Separated Values (CSV) are the two file type extensions used to load a set of data. A .tsv file will have tab separated values whereas .csv file has comma separated fields. 

import pandas as pd
tsv_file='/content/drive/My Drive/weekly_housing_market_data_most_recent.tsv'
housing_df = pd.read_table(tsv_file,sep='\t')
housing_df.to_csv('housing.csv',index=False)
housing_df.head()

# Commented out IPython magic to ensure Python compatibility.
#Installing libraries to support analysis and graphical visualization
import numpy as np
import pandas as pd
import seaborn as sns
# %matplotlib inline
import matplotlib.pyplot as plt
plt.style.use('seaborn-whitegrid')

# Sorting values first alphabetically by region_name and then in ascending order by period_begin
housing_df.sort_values(['region_name', 'period_begin'], ascending=[True, True], inplace=True)
housing_df.head()

# Checking the size of the dataset
housing_df.shape

"""In this case, the dataset has 904608 columns and 78 rows"""

#To check the 78 rows of the dataset
list(housing_df)

#understanding the quality of the dataset - quantity of non-empty rows
def NaN_percent(housing_df, column_name):
    row_count = housing_df[column_name].shape[0]
    empty_values = row_count - housing_df[column_name].count()
    return (100.0*empty_values)/row_count
    
for i in list(housing_df):
    print(i +': ' + str(NaN_percent(housing_df,i))+'%')

#Alternative method to show null values
print(housing_df.isnull().sum().to_string())

#Selecting columns that are relevant to the research
df1 = housing_df[['region_name', 'period_begin', 'period_end', 'duration', 'total_homes_sold', 'average_homes_sold', 'inventory', 'homes_delisted', 'median_sale_price']]
df1.head()

#Drop the rows where at least one element is missing:
df1.dropna(inplace = True)

#Checking whether there is an adequate number of rows divided per time period to scale down to 1 weeks.
print(df1['duration'].value_counts())

#Selecting data that shows a period of 1 weeks for analysis
 = df1.loc[housing_df["duration"] == "1 weeks"]
df2.head()

#Adding a column that narrows down the period to YYYY-MM (year and month). This will make visualization easier to read.
df2['Year'] = df2.period_begin.apply(lambda x: x[0:7])
df2.head()

#Sorting the dataset, first alphabetically by region_name and then oldest-to-newest for period_begin
df2.sort_values(['region_name', 'period_begin'], ascending=[True, True], inplace=True)
df2.head()

#Creating a pivot table to sum the total homes sold for all counties, with an index of period_begin
counties_by_total = df2.pivot_table(index='period_begin', columns='region_name', values='total_homes_sold', aggfunc='sum')

#Adding a column at the end showing the sum of total homes sold for all given counties, since the analysis shows the impact at a aggregate level for all counties. 
counties_by_total['sum'] = counties_by_total.sum(numeric_only=True, axis=1)
counties_by_total.head()

#Using matplotlib to visualize the graph for total homes sold for all regions over the 2017-2020 time period
counties_by_total['sum'].plot(figsize=(20,3))
plt.ylabel('Total Homes Sold in Thousands')
plt.xlabel('Time Period')

#Creating a pivot table to sum the the number of homes available on the market(inventory) for all counties, with an index of period_begin
counties_by_inventory = df2.pivot_table(index='period_begin', columns='region_name', values='inventory', aggfunc='sum')

#Adding a column at the end showing the sum of inventory for all given counties
counties_by_inventory['sum'] = counties_by_inventory.sum(numeric_only=True, axis=1)
counties_by_inventory.head()

#Using matplotlib to visualize the graph for the number of homes available on the market(inventory) for all regions over the 2017-2020 time period
counties_by_inventory['sum'].plot(figsize=(20,3))
plt.ylabel('Inventory of Homes in Millions')
plt.xlabel('Time Period')

#Creating a pivot table to sum the the number of homes delisted for all counties, with an index of period_begin
counties_homesdelisted = df2.pivot_table(index='period_begin', columns='region_name', values='homes_delisted', aggfunc='sum')

#Adding a column at the end showing the sum of delisted for all given counties
counties_homesdelisted['sum'] = counties_homesdelisted.sum(numeric_only=True, axis=1)
counties_homesdelisted.head()

#Using matplotlib to visualize the graph for number of homes delisted regions over the 2017-2020 time period
counties_homesdelisted['sum'].plot(figsize=(20,3))
plt.ylabel('Homes Delisted in Thousands')
plt.xlabel('Time Period')

#Creating a pivot table to sum the total homes sold for all counties, with an index of period_begin by YYYY-MM
total_year = df2.pivot_table(index='Year', columns='region_name', values='total_homes_sold', aggfunc='sum')

#Adding a column at the end showing the sum of total homes sold for all given counties
total_year['sum'] = total_year.sum(numeric_only=True, axis=1)
total_year.head()

#Using matplotlib to visualize the graph for total homes sold for all regions over the 2017-2020 time period by YYYY-MM
total_year['sum'].plot(figsize=(20,3))
plt.ylabel('Total Homes Sold in Millions')
plt.xlabel('Time Period')

#Creating a pivot table to sum the inventory of homes for all counties, with an index of period_begin by YYYY-MM
inventory_year = df2.pivot_table(index='Year', columns='region_name', values='inventory', aggfunc='sum')

#Adding a column at the end showing the sum of inventory of homes for all given counties
inventory_year['sum'] = inventory_year.sum(numeric_only=True, axis=1)
inventory_year.head()

#Using matplotlib to visualize the graph for inventory for all regions over the 2017-2020 time period by YYYY-MM
inventory_year['sum'].plot(figsize=(20,3))
plt.ylabel('Inventory of Homes in Millions')
plt.xlabel('Time Period')

#Creating a pivot table to sum homes delisted for all counties, with an index of period_begin by YYYY-MM
deslisted_year = df2.pivot_table(index='Year', columns='region_name', values='homes_delisted', aggfunc='sum')

#Adding a column at the end showing the sum of homes delisted for all given counties
deslisted_year['sum'] = deslisted_year.sum(numeric_only=True, axis=1)
deslisted_year.head()

#Using matplotlib to visualize the graph for homes delisted for all regions over the 2017-2020 time period by YYYY-MM
deslisted_year['sum'].plot(figsize=(20,3))
plt.ylabel('Homes Delisted in Thousands')
plt.xlabel('Time Period')